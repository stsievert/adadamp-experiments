{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58b8326-6489-4964-9303-c14e2f2ac797",
   "metadata": {},
   "source": [
    "This notebook will do the following:\n",
    "\n",
    "1. Download pretrained model (automatically w/ PyTorch):\n",
    "    * https://huggingface.co/google/vit-base-patch16-224\n",
    "2. Download data https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/\n",
    "    * a PyTorch FGVCAircraft class also exists, but doesn't use the supplied bounding boxes.\n",
    "    * Instead, let's manually pass the images to `ViTImageProcessor` and read the label (\"variant\") ourselves\n",
    "3. Process all the images in the dataset\n",
    "    * Pass image through model, collect intermediate layer\n",
    "4. Write dataset to disk.\n",
    "    * labels: JSON file. `ID: label` in `labels_*.json`\n",
    "    * Cropped images: In `cropped`, filename is `{ID}.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4ba8a-546f-466d-b717-4f246623b53f",
   "metadata": {},
   "source": [
    "Dataset notes:\n",
    "\n",
    "- The (main) aircraft in each image is annotated with a tight bounding box and a hierarchical airplane model label.\n",
    "- Annotation level: Variant, e.g. Boeing 737-700. A variant collapses all the models that are visually indistinguishable into one class. The dataset comprises 102 different variants.\n",
    "- Comes with train/test split already\n",
    "- The top-left pixel of an image has coordinate (1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda8af49-e235-4ebb-b4d6-0d5c74b73524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "LIMIT = asyncio.Semaphore(100)\n",
    "\n",
    "BBox = Tuple[int, int, int, int]\n",
    "Feature = List[float]\n",
    "\n",
    "DIR = Path(\".\").absolute()\n",
    "DS_DIR = DIR / \"dataset\" / \"fgvc-aircraft-2013b\"  / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55965b8c-f355-48f6-a024-d52a04243094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(f: Path):\n",
    "    text = f.read_text().split(\"\\n\")\n",
    "    return {int(x.split(\" \")[0]): \" \".join(x.split(\" \")[1:]) for x in text if x}\n",
    "    \n",
    "train_labels = get_labels(DS_DIR / \"images_family_trainval.txt\")\n",
    "test_labels = get_labels(DS_DIR / \"images_family_test.txt\")\n",
    "assert len(test_labels) + len(train_labels) == 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60bfc9d6-3ad0-4862-9b42-ff38f5a793cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(f: Path) -> Dict[int, BBox]:\n",
    "    raw = f.read_text().split(\"\\n\")\n",
    "    rare = {int(x.split(\" \")[0]): tuple([int(_x) for _x in x.split(\" \")[1:]]) for x in raw if x}\n",
    "    mrare = {id: tuple([x - 1 for x in box]) for id, box in rare.items()}\n",
    "    return mrare\n",
    "\n",
    "async def _crop_images(files: List[Path], bbox: List[BBox]) -> List[Image]:\n",
    "    async def open(f: Path) -> Image:\n",
    "        async with LIMIT:\n",
    "            return Image.open(f)\n",
    "    images = await asyncio.gather(*[open(f) for f in files])\n",
    "    images = [img.crop(box)  for box, img in zip(bbox, images)]\n",
    "    return images\n",
    "\n",
    "async def crop_images(\n",
    "    raw_images: List[Path],\n",
    "    bboxes: List[BBox],\n",
    "    ids: List[int],\n",
    "    batch=64,\n",
    "    save=False,\n",
    ") -> Dict[int, Feature]:\n",
    "    feats = dict()\n",
    "    for k in itertools.count():\n",
    "        good_id = ids[k * batch:(k + 1) * batch]\n",
    "        if not len(good_id):\n",
    "            break\n",
    "        bimg = [raw_images[k] for k in good_id]\n",
    "        bbbox = [bboxes[k] for k in good_id]\n",
    "        assert len(bimg) == len(bbbox)\n",
    "        bimgs2 = await _crop_images(bimg, bbbox)\n",
    "\n",
    "        if save:\n",
    "            for fname, img in zip(good_id, bimgs2):\n",
    "                img.save(DIR / \"dataset\" / \"cropped\" / f\"{fname}.jpg\")\n",
    "        \n",
    "        # process images through model\n",
    "        # write to disk\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c404a94-ce3b-4334-9939-099094cdac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = {int(f.name.replace(\".jpg\", \"\")): f for f in (DS_DIR / \"images\").glob(\"*.jpg\")}\n",
    "ids = [int(x) for x in sorted(raw_images.keys())]\n",
    "assert len(ids) == 10_000\n",
    "assert len(raw_images) == 10_000\n",
    "\n",
    "bboxes = get_boxes(DS_DIR / \"images_box.txt\")\n",
    "assert len(bboxes) == 10_000\n",
    "\n",
    "await crop_images(raw_images, bboxes, ids, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07cb4d5d-a5be-41fa-8d06-03101f61f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(DIR / \"dataset\" / \"labels_test.json\", \"w\") as f:\n",
    "    json.dump(test_labels, f)\n",
    "with open(DIR / \"dataset\" / \"labels_train.json\", \"w\") as f:\n",
    "    json.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92380c-8972-49b4-a90e-7d48d2c56128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:finetune]",
   "language": "python",
   "name": "conda-env-finetune-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
